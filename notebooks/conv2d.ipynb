{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e318f6-d47c-4584-80bc-107028c4412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn.functional import conv2d\n",
    "from torch.utils.cpp_extension import load_inline\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a5e42f4-76c5-4c87-a957-79a263c111c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_handler(prof):\n",
    "    print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=-1))\n",
    "    prof.export_chrome_trace(\"tmp/test_trace_\" + str(prof.step_num) + \".json\")\n",
    "\n",
    "def profile_func(func, *tensors, trace_handler=trace_handler):\n",
    "        \n",
    "    \"\"\" In this example with wait=1, warmup=1, active=2, repeat=1, profiler will skip the first step/iteration,\n",
    "        start warming up on the second, record the third and the forth iterations, after which the trace will become available\n",
    "        and on_trace_ready (when set) is called; the cycle repeats starting with the next step \"\"\"\n",
    "    with torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=2, repeat=1), on_trace_ready=trace_handler\n",
    "        # on_trace_ready=torch.profiler.tensorboard_trace_handler('./log')\n",
    "        # used when outputting for tensorboard\n",
    "        ) as p:\n",
    "            for iter in range(10):\n",
    "                func(*tensors)\n",
    "                # send a signal to the profiler that the next iteration has started\n",
    "                p.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fdf59e1-0712-422d-a33a-f848281211a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_source = '''\n",
    "#define IN_TILE_DIM 5\n",
    "#define OUT_TILE_DIM ((IN_TILE_DIM) - 2 * (FILTER_RADIUS))\n",
    "#define FILTER_RADIUS 1\n",
    "\n",
    "__constant__ float F_c[2*FILTER_RADIUS+1][2*FILTER_RADIUS+1] {{1,2,3},\n",
    "                                                              {4,5,6},\n",
    "                                                              {7,8,9}};\n",
    "                                                              \n",
    "__global__ void convolution_tiled_2D_const_mem_kernel(float* N, float* P, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  int width, int height) {\n",
    "\tint col = blockIdx.x * OUT_TILE_DIM + threadIdx.x - FILTER_RADIUS;\n",
    "\tint row = blockIdx.y * OUT_TILE_DIM + threadIdx.y - FILTER_RADIUS;\n",
    "\t// Loading input tile\n",
    "\t__shared__ float N_s[IN_TILE_DIM][IN_TILE_DIM];\n",
    "\tif(row>=0 && row<height && col>=0 && col<height){\n",
    "\t\tN_s[threadIdx.y][threadIdx.x] = N[row * width + col];\n",
    "\t} else {\n",
    "\t\tN_s[threadIdx.y][threadIdx.x] = 0.0f;\n",
    "\t}\n",
    "\t__syncthreads();\n",
    "\t// Caclulating output elements\n",
    "\tint tileCol = threadIdx.x - FILTER_RADIUS;\n",
    "\tint tileRow = threadIdx.y - FILTER_RADIUS;\n",
    "\t// Turning off the threads at the edges of the block\n",
    "\tif (col >= 0 && col < width && row >=0 && row < width) {\n",
    "\t\tif (tileCol >= 0 && tileCol < OUT_TILE_DIM && tileRow >= 0 \n",
    "\t\t\t\t\t\t\t\t&& tileRow < OUT_TILE_DIM) { \n",
    "\t\t\tfloat Pvalue = 0.0f;\n",
    "\t\t\tfor (int fRow = 0; fRow < 2 * FILTER_RADIUS + 1; fRow++) {\n",
    "\t\t\t\tfor (int fCol = 0; fCol < 2 * FILTER_RADIUS + 1; fCol++) {\n",
    "\t\t\t\t\tPvalue += F_c[fRow][fCol] * N_s[tileRow+fRow][tileCol+fCol];\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t\tP[row*width+col] = Pvalue;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "torch::Tensor conv2d(torch::Tensor matrix) {\n",
    "    const auto height = matrix.size(0);\n",
    "    const auto width = matrix.size(1);\n",
    "\n",
    "    auto result = torch::empty_like(matrix);\n",
    "\n",
    "    dim3 threads_per_block(IN_TILE_DIM, IN_TILE_DIM); // launches thread blocks whose dimension matches that of the input tiles\n",
    "    dim3 number_of_blocks((width + threads_per_block.x - 1) / threads_per_block.x,\n",
    "                          (height + threads_per_block.y - 1) / threads_per_block.y);\n",
    "\n",
    "    convolution_tiled_2D_const_mem_kernel<<<number_of_blocks, threads_per_block>>>(\n",
    "        matrix.data_ptr<float>(), result.data_ptr<float>(), width, height);\n",
    "\n",
    "    return result;\n",
    "    }\n",
    "'''\n",
    "\n",
    "cpp_source = \"torch::Tensor conv2d(torch::Tensor matrix);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a287a6a9-cdb2-464a-98b1-c0bb3909583d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/panagiotis/Desktop/dev/git/cuda/tmp/conv2d_extension_v2.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m conv2d_extension \u001b[38;5;241m=\u001b[39m \u001b[43mload_inline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconv2d_extension\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcpp_sources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpp_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcuda_sources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcuda_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconv2d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-O2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"-allow-unsupported-compiler\",\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"'--expt-relaxed-constexpr'\",\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1646\u001b[0m, in \u001b[0;36mload_inline\u001b[0;34m(name, cpp_sources, cuda_sources, functions, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, with_pytorch_error_handling, keep_intermediates, use_pch)\u001b[0m\n\u001b[1;32m   1642\u001b[0m     _maybe_write(cuda_source_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cuda_sources))\n\u001b[1;32m   1644\u001b[0m     sources\u001b[38;5;241m.\u001b[39mappend(cuda_source_path)\n\u001b[0;32m-> 1646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1746\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_standalone:\n\u001b[1;32m   1744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_exec_path(name, build_directory)\n\u001b[0;32m-> 1746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_import_module_from_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2140\u001b[0m, in \u001b[0;36m_import_module_from_library\u001b[0;34m(module_name, path, is_python_module)\u001b[0m\n\u001b[1;32m   2138\u001b[0m spec \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mspec_from_file_location(module_name, filepath)\n\u001b[1;32m   2139\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2140\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_from_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2141\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec\u001b[38;5;241m.\u001b[39mloader, importlib\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mLoader)\n\u001b[1;32m   2142\u001b[0m spec\u001b[38;5;241m.\u001b[39mloader\u001b[38;5;241m.\u001b[39mexec_module(module)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:813\u001b[0m, in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1288\u001b[0m, in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/panagiotis/Desktop/dev/git/cuda/tmp/conv2d_extension_v2.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "conv2d_extension = load_inline(\n",
    "    name=\"conv2d_extension\",\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=[\"conv2d\"],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\n",
    "        \"-O2\",\n",
    "        # \"-allow-unsupported-compiler\",\n",
    "        # \"'--expt-relaxed-constexpr'\",\n",
    "    ],\n",
    "    build_directory=\"tmp\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f701cae-5f46-4a68-b7d1-685390bf3cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 94., 154., 106.],\n",
      "        [186., 285., 186.],\n",
      "        [106., 154.,  94.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9]], device='cuda')\n",
    "print(conv2d_extension.conv2d(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e332f9f1-105f-45b7-af66-7007fbe455b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.63 µs ± 326 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "conv2d_extension.conv2d(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e42876-4f40-491a-aef4-e04c0a829b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = torch.tensor([[1., 2., 3.],[4., 5., 6.],[7.,8.,9.]], device='cuda')\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1bc248a-7fc6-484b-931b-1a50b80410d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 94., 154., 106.],\n",
       "          [186., 285., 186.],\n",
       "          [106., 154.,  94.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(a.reshape((1,1,3,3)), weight.reshape((1,1,3,3)), padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e29941e0-ffcf-48ff-a3ac-a76adf2e50be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8 µs ± 956 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "conv2d(a.reshape((1,1,3,3)), weight.reshape((1,1,3,3)), padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304035ea-0a8e-4f3f-ac4b-83a6c99dfc44",
   "metadata": {},
   "source": [
    "### Try on a bigger matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c23b686-4ba7-4a7c-a199-b056401736a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_100 = torch.randint(100, (100, 100)).to('cuda').float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ddacabe-c4a8-493b-bda0-836c54fad81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1892., 2686., 2242.,  ..., 1579., 1087.,  584.],\n",
       "        [2269., 3042., 2179.,  ..., 2061., 1487.,  991.],\n",
       "        [2435., 3080., 2394.,  ..., 2737., 2559., 1880.],\n",
       "        ...,\n",
       "        [2079., 2336., 1982.,  ..., 1515., 1633., 1080.],\n",
       "        [1703., 2401., 2168.,  ..., 2826., 2959., 1857.],\n",
       "        [ 724., 1169., 1061.,  ..., 1452., 1615.,  977.]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_extension.conv2d(a_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff148e8a-8ccb-4d46-867a-240dee733134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.76 µs ± 612 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "conv2d_extension.conv2d(a_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62475bdd-afaa-4b4e-a31c-e5512c8b06e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1892., 2686., 2242.,  ..., 1579., 1087.,  584.],\n",
       "          [2269., 3042., 2179.,  ..., 2061., 1487.,  991.],\n",
       "          [2435., 3080., 2394.,  ..., 2737., 2559., 1880.],\n",
       "          ...,\n",
       "          [2079., 2336., 1982.,  ..., 1515., 1633., 1080.],\n",
       "          [1703., 2401., 2168.,  ..., 2826., 2959., 1857.],\n",
       "          [ 724., 1169., 1061.,  ..., 1452., 1615.,  977.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(a_100.reshape((1,1,100,100)), weight.reshape((1,1,3,3)), padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec26366-e752-4c17-a90b-3d119a8758be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.7 µs ± 926 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "conv2d(a_100.reshape((1,1,100,100)), weight.reshape((1,1,3,3)), padding='same')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
