{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07ca860-a59f-46d7-bc91-113e451e76cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.cpp_extension import load_inline\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85b7ee0-21bb-4a26-bb1c-1f268251c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_handler(prof):\n",
    "    print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=-1))\n",
    "    prof.export_chrome_trace(\"tmp/test_trace_\" + str(prof.step_num) + \".json\")\n",
    "\n",
    "def profile_func(func, *tensors, trace_handler=trace_handler):\n",
    "        \n",
    "    \"\"\" In this example with wait=1, warmup=1, active=2, repeat=1, profiler will skip the first step/iteration,\n",
    "        start warming up on the second, record the third and the forth iterations, after which the trace will become available\n",
    "        and on_trace_ready (when set) is called; the cycle repeats starting with the next step \"\"\"\n",
    "    with torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=2, repeat=1), on_trace_ready=trace_handler\n",
    "        # on_trace_ready=torch.profiler.tensorboard_trace_handler('./log')\n",
    "        # used when outputting for tensorboard\n",
    "        ) as p:\n",
    "            for iter in range(10):\n",
    "                func(*tensors)\n",
    "                # send a signal to the profiler that the next iteration has started\n",
    "                p.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7453d3bb-a29a-4603-a0bb-25b3ea97c26f",
   "metadata": {},
   "source": [
    "### Simple paralellel histogram with atomic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22f45449-6606-4b0d-8e4b-14d7a6d20bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_source = '''\n",
    "#include <stdio.h>\n",
    "#include <torch/extension.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "#include <cuda.h>\n",
    "#include <ATen/cuda/Atomic.cuh>`\n",
    "\n",
    "__global__ void histo_kernel(const int* data, int length, int* histo) {\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    // Ensure `i` is within bounds before accessing data and histo\n",
    "    if (i < length) {\n",
    "        int alphabet_position = data[i] - 97; // Python unicode system for lowercase letters is [97,122]\n",
    "        // Validate alphabet_position to be within the valid range\n",
    "        if (0 <= alphabet_position && alphabet_position <= 26) { \n",
    "            // Use atomicAdd for thread-safe histogram updates\n",
    "            gpuAtomicAdd(&histo[alphabet_position], 1);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "torch::Tensor parallel_histo(torch::Tensor data) {\n",
    "\n",
    "    auto options = torch::TensorOptions().device(torch::kCUDA, 0).dtype(torch::kInt32);\n",
    "\n",
    "    auto length = data.size(0);\n",
    "    auto histo = torch::zeros({26}, options);\n",
    "\n",
    "    // Launch the kernel with necessary configuration\n",
    "    int num_blocks = (length + 127) / 128; // Dynamic block allocation\n",
    "    histo_kernel<<<num_blocks, 128>>>(data.data_ptr<int>(), length, histo.data_ptr<int>());\n",
    "    return histo;\n",
    "}\n",
    "'''\n",
    "\n",
    "cpp_source = \"torch::Tensor parallel_histo(torch::Tensor data);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbb1d250-e87e-4f7c-ac3e-0bc6b42437c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_histo_extension = load_inline(\n",
    "    name='parallel_histo_extension',\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=['parallel_histo'],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\"-O2\"],\n",
    "    build_directory='tmp',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bb4bc037-d737-414a-80a5-7c7fcdfcce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Odio ut sem nulla pharetra diam sit amet nisl. Sed risus pretium quam vulputate dignissim. Sapien pellentesque habitant morbi tristique senectus. Varius sit amet mattis vulputate enim nulla aliquet. Tristique et egestas quis ipsum suspendisse ultrices gravida dictum fusce. Blandit cursus risus at ultrices mi. Sem fringilla ut morbi tincidunt. Sit amet nisl purus in mollis. Neque viverra justo nec ultrices. In hendrerit gravida rutrum quisque non tellus. Nulla porttitor massa id neque. Et egestas quis ipsum suspendisse ultrices gravida dictum fusce. Ultrices gravida dictum fusce ut placerat orci nulla pellentesque dignissim.'\n",
    "t_data = torch.tensor([x for x in data.encode('utf-8')], device='cuda', dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1a545f3-8050-4742-b070-11c9c8e7100a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44,  4, 21, 26, 64,  4, 11,  3, 71,  1,  0, 35, 29, 31, 19, 17, 13, 38,\n",
       "        60, 59, 57,  8,  0,  0,  0,  0], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_histo_extension.parallel_histo(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d93fec7b-91a7-4eb9-8967-9f2cb147a8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.55 µs ± 71.1 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "parallel_histo_extension.parallel_histo(t_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdcebc7-b526-455a-80cd-75cc9c0e6cad",
   "metadata": {},
   "source": [
    "Check results with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1c03655-601f-4f9a-b505-4f7348ebfcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 1 2 0 1 2 5 0 0 1 1 2 1 0 0 2 3 2 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "arr = t_data.detach().cpu().numpy()\n",
    "letters_arr = np.array([x - 97 for x in arr if x >= 97])\n",
    "\n",
    "unique, counts = np.unique(letters_arr, return_counts=True)\n",
    "np_hist = np.zeros((26,), dtype='int')\n",
    "for idx, elem in zip(unique,counts):\n",
    "    np_hist[idx] = elem\n",
    "\n",
    "print(np_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c548582-79b9-4851-b526-b3ce98f81070",
   "metadata": {},
   "source": [
    "### Parallel histogram with Privatization in shared memory (contiguous partitioning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c23ca0b-9be0-44da-a7d7-1adf6a3ebbae",
   "metadata": {},
   "source": [
    "![](images/contigous.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e53df0-f1d4-4aa1-98b0-e1994e59cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_source = '''\n",
    "#include <stdio.h>\n",
    "#include <torch/extension.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "#include <cuda.h>\n",
    "#include <ATen/cuda/Atomic.cuh>`\n",
    "\n",
    "#define HIST_LENGTH 26\n",
    "#define NUM_BINS 26\n",
    "#define CFACTOR 3\n",
    "\n",
    "__global__ void histo_kernel(const int* data, int length, int* histo) {\n",
    "\n",
    "    // Initialize private bins. \n",
    "    __shared__ unsigned int histo_s[HIST_LENGTH];\n",
    "    \n",
    "    for(unsigned int binIdx=threadIdx.x; binIdx<NUM_BINS; binIdx+= blockDim.x) {\n",
    "    // Every thread will fill 1 position until all positions in the shared array are filled with zeros\n",
    "        histo_s[binIdx] = 0u;\n",
    "    }\n",
    "    __syncthreads(); // Wait for all threads to finish the initialization\n",
    "    \n",
    "    // Histogram\n",
    "    unsigned int tid = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    for(unsigned int i=tid*CFACTOR; i<min((tid+1)*CFACTOR,length); ++i) {\n",
    "        int alphabet_position = data[i] - 97; // Python unicode system for lowercase letters is [97,122]\n",
    "        // Validate alphabet_position to be within the valid range\n",
    "        if (0 <= alphabet_position && alphabet_position <= 26) { \n",
    "            // Use atomicAdd for thread-safe histogram updates\n",
    "            atomicAdd(&histo_s[alphabet_position], 1);\n",
    "        }\n",
    "    }\n",
    "    __syncthreads();\n",
    "    // Commit to global memory\n",
    "    for(unsigned int binIdx=threadIdx.x; binIdx<NUM_BINS; binIdx+=blockDim.x){\n",
    "        unsigned int binValue = histo_s[binIdx];\n",
    "        if(binValue > 0) { \n",
    "            atomicAdd(&(histo[binIdx]), binValue);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "torch::Tensor parallel_histo(torch::Tensor data) {\n",
    "\n",
    "    auto options = torch::TensorOptions().device(torch::kCUDA, 0).dtype(torch::kInt32);\n",
    "\n",
    "    auto length = data.size(0);\n",
    "    auto histo = torch::zeros({26}, options);\n",
    "\n",
    "    // Launch the kernel with necessary configuration\n",
    "    // We define 3 blocks each of which will have a private copy\n",
    "    histo_kernel<<<3, 128>>>(data.data_ptr<int>(), length, histo.data_ptr<int>());\n",
    "    return histo;\n",
    "}\n",
    "'''\n",
    "\n",
    "cpp_source = \"torch::Tensor parallel_histo(torch::Tensor data);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6389a5cd-10b1-4189-982d-752aa2d0fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Odio ut sem nulla pharetra diam sit amet nisl. Sed risus pretium quam vulputate dignissim. Sapien pellentesque habitant morbi tristique senectus. Varius sit amet mattis vulputate enim nulla aliquet. Tristique et egestas quis ipsum suspendisse ultrices gravida dictum fusce. Blandit cursus risus at ultrices mi. Sem fringilla ut morbi tincidunt. Sit amet nisl purus in mollis. Neque viverra justo nec ultrices. In hendrerit gravida rutrum quisque non tellus. Nulla porttitor massa id neque. Et egestas quis ipsum suspendisse ultrices gravida dictum fusce. Ultrices gravida dictum fusce ut placerat orci nulla pellentesque dignissim.\"\n",
    "t_data = torch.tensor([x for x in data.encode('utf-8')], device='cuda', dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf9457f-b837-427e-8e41-2ea16b794e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_histo_extension = load_inline(\n",
    "    name='parallel_histo_extension',\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=['parallel_histo'],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\"-O2\"],\n",
    "    build_directory='tmp',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49ae8223-4ec1-4a20-b605-1da6e48d9eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44,  4, 21, 26, 64,  4, 11,  3, 71,  1,  0, 35, 29, 31, 19, 17, 13, 38,\n",
       "        60, 59, 57,  8,  0,  0,  0,  0], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_histo_extension.parallel_histo(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4781f6bf-6e03-497a-a4fe-3d1c8c496bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.23 µs ± 39.1 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "parallel_histo_extension.parallel_histo(t_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164fcdf2-234a-4dba-b328-0bf413b2b349",
   "metadata": {},
   "source": [
    "### Parallel histogram with Privatization in shared memory (interleaved partitioning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ecc76-daed-4474-a33c-dbfbced8f805",
   "metadata": {},
   "source": [
    "![](images/interleaved.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aad78284-d0ca-4139-b0c0-9663e37ffecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_source = '''\n",
    "#include <stdio.h>\n",
    "#include <torch/extension.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "#include <cuda.h>\n",
    "#include <ATen/cuda/Atomic.cuh>`\n",
    "\n",
    "#define HIST_LENGTH 26\n",
    "#define NUM_BINS 26\n",
    "#define CFACTOR 3\n",
    "\n",
    "__global__ void histo_kernel(const int* data, int length, int* histo) {\n",
    "\n",
    "    // Initialize private bins. \n",
    "    __shared__ unsigned int histo_s[HIST_LENGTH];\n",
    "    \n",
    "    for(unsigned int binIdx=threadIdx.x; binIdx<NUM_BINS; binIdx+= blockDim.x) {\n",
    "    // Every thread will fill 1 position until all positions in the shared array are filled with zeros\n",
    "        histo_s[binIdx] = 0u;\n",
    "    }\n",
    "    __syncthreads(); // Wait for all threads to finish the initialization\n",
    "    \n",
    "    // Histogram\n",
    "    unsigned int tid = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    for(unsigned int i= tid; i<length; i += blockDim.x*gridDim.x) {\n",
    "        int alphabet_position = data[i] - 97; // Python unicode system for lowercase letters is [97,122]\n",
    "        // Validate alphabet_position to be within the valid range\n",
    "        if (0 <= alphabet_position && alphabet_position <= 26) { \n",
    "            // Use atomicAdd for thread-safe histogram updates\n",
    "            atomicAdd(&histo_s[alphabet_position], 1);\n",
    "        }\n",
    "    }\n",
    "    __syncthreads();\n",
    "    // Commit to global memory\n",
    "    for(unsigned int binIdx=threadIdx.x; binIdx<NUM_BINS; binIdx+=blockDim.x){\n",
    "        unsigned int binValue = histo_s[binIdx];\n",
    "        if(binValue > 0) { \n",
    "            atomicAdd(&(histo[binIdx]), binValue);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "torch::Tensor parallel_histo(torch::Tensor data) {\n",
    "\n",
    "    auto options = torch::TensorOptions().device(torch::kCUDA, 0).dtype(torch::kInt32);\n",
    "\n",
    "    auto length = data.size(0);\n",
    "    auto histo = torch::zeros({26}, options);\n",
    "\n",
    "    // Launch the kernel with necessary configuration\n",
    "    // We define 3 blocks each of which will have a private copy\n",
    "    histo_kernel<<<3, 128>>>(data.data_ptr<int>(), length, histo.data_ptr<int>());\n",
    "    return histo;\n",
    "}\n",
    "'''\n",
    "\n",
    "cpp_source = \"torch::Tensor parallel_histo(torch::Tensor data);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6f27df8-c3c7-4326-b480-ed3af3d2399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_histo_extension = load_inline(\n",
    "    name='parallel_histo_extension',\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=['parallel_histo'],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\"-O2\"],\n",
    "    build_directory='tmp',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f50f85e3-001e-4f28-ac6d-3d3b1c5ee58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44,  4, 21, 26, 64,  4, 11,  3, 71,  1,  0, 35, 29, 31, 19, 17, 13, 38,\n",
       "        60, 59, 57,  8,  0,  0,  0,  0], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_histo_extension.parallel_histo(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da506270-377b-43bb-b696-d035a86a81b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.24 µs ± 264 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "parallel_histo_extension.parallel_histo(t_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
