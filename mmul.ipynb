{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c389c37-5b97-4e92-a975-526b67a79f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.cpp_extension import load_inline\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c9d73dc-65a7-4628-8d8c-8e3cf0883999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_handler(prof):\n",
    "    print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=-1))\n",
    "    prof.export_chrome_trace(\"tmp/test_trace_\" + str(prof.step_num) + \".json\")\n",
    "\n",
    "def profile_func(func, *tensors, trace_handler=trace_handler):\n",
    "        \n",
    "    \"\"\" In this example with wait=1, warmup=1, active=2, repeat=1, profiler will skip the first step/iteration,\n",
    "        start warming up on the second, record the third and the forth iterations, after which the trace will become available\n",
    "        and on_trace_ready (when set) is called; the cycle repeats starting with the next step \"\"\"\n",
    "    with torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=2, repeat=1), on_trace_ready=trace_handler\n",
    "        # on_trace_ready=torch.profiler.tensorboard_trace_handler('./log')\n",
    "        # used when outputting for tensorboard\n",
    "        ) as p:\n",
    "            for iter in range(10):\n",
    "                func(*tensors)\n",
    "                # send a signal to the profiler that the next iteration has started\n",
    "                p.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31cb0f34-cc99-4867-861d-125146d23009",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_source = '''\n",
    "__global__ void square_matrix_kernel(const float* matrix, float* result, int width, int height) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (row < height && col < width) {\n",
    "        int idx = row * width + col;\n",
    "        result[idx] = matrix[idx] * matrix[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "torch::Tensor square_matrix(torch::Tensor matrix) {\n",
    "    const auto height = matrix.size(0);\n",
    "    const auto width = matrix.size(1);\n",
    "\n",
    "    auto result = torch::empty_like(matrix);\n",
    "\n",
    "    dim3 threads_per_block(16, 16);\n",
    "    dim3 number_of_blocks((width + threads_per_block.x - 1) / threads_per_block.x,\n",
    "                          (height + threads_per_block.y - 1) / threads_per_block.y);\n",
    "\n",
    "    square_matrix_kernel<<<number_of_blocks, threads_per_block>>>(\n",
    "        matrix.data_ptr<float>(), result.data_ptr<float>(), width, height);\n",
    "\n",
    "    return result;\n",
    "    }\n",
    "'''\n",
    "\n",
    "cpp_source = \"torch::Tensor square_matrix(torch::Tensor matrix);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe03ce1-6364-49bb-8bf4-8edecc00ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "square_matrix_extension = load_inline(\n",
    "    name='square_matrix_extension',\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=['square_matrix'],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\"-O2\"],\n",
    "    build_directory='tmp',\n",
    "    # extra_cuda_cflags=['--expt-relaxed-constexpr']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ffd5b1c-603d-449e-b207-2aeee796c04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1., 2., 3.], [4., 5., 6.]], device='cuda')\n",
    "print(square_matrix_extension.square_matrix(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad82eeb-b97d-4d4e-999e-b4767d74ebe9",
   "metadata": {},
   "source": [
    "### Matrix mul row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e97417-c082-440e-9d8c-3443b88e53aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_source = \"\"\"\n",
    "__global__ void matrix_mul_kernel(const float* matrix_a, const float* matrix_b, float* result, \n",
    "                                  int width){\n",
    "\t\n",
    "\tint row = threadIdx.x;\n",
    " \n",
    "\t// Check for thread out of bound access\n",
    "\tif (row < width){\n",
    "        for (int col = 0; col < width; ++col) {\n",
    "            float sum = 0;\t\n",
    "            for (int k = 0; k < width; ++k){\n",
    "    \t\t\tsum += matrix_a[row * width + k] * matrix_b[k * width + col];\n",
    "    \t\t}\n",
    "    \t\tresult[row * width + col] = sum;\n",
    "    \t}\n",
    "    }\n",
    "}\n",
    "\n",
    "torch::Tensor matrix_mul(torch::Tensor matrix_a, torch::Tensor matrix_b){\n",
    "\n",
    "    const auto width = matrix_a.size(0);\n",
    "    auto result =  torch::empty_like(matrix_a);\n",
    "\n",
    "    matrix_mul_kernel<<<1, width>>>(\n",
    "        matrix_a.data_ptr<float>(), matrix_b.data_ptr<float>(), result.data_ptr<float>(), width); // assume square matrix\n",
    "    return result;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "cpp_source = \"torch::Tensor matrix_mul(torch::Tensor matrix_a, torch::Tensor matrix_b);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c68fafb-7f69-4bd9-bc02-547eac993f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_mul_extension = load_inline(\n",
    "    name='matrix_mul_extension',\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=['matrix_mul'],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\"-O2\"],\n",
    "    build_directory='tmp',\n",
    "    # extra_cuda_cflags=['--expt-relaxed-constexpr']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eeb014a-ab91-4cc8-874d-c25c68cb33bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 30.,  36.,  42.],\n",
      "        [ 66.,  81.,  96.],\n",
      "        [102., 126., 150.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1., 2., 3], [4., 5., 6.], [7., 8., 9.]], device='cuda')\n",
    "b = torch.tensor([[1., 2., 3], [4., 5., 6.], [7., 8., 9.]], device='cuda')\n",
    "print(matrix_mul_extension.matrix_mul(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d37d06af-59e2-4565-abfd-986c360aeae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_func(matrix_mul_extension.matrix_mul, *[a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52a6865b-6a33-4a51-afd0-f131cd943620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 30.,  36.,  42.],\n",
       "        [ 66.,  81.,  96.],\n",
       "        [102., 126., 150.]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4af5499-4929-4061-a7f8-1c2b573483f3",
   "metadata": {},
   "source": [
    "### Matrix mul column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcdff5f4-039f-4cb1-869a-31deb7d5c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_source = \"\"\"\n",
    "__global__ void matrix_mul_kernel(const float* matrix_a, const float* matrix_b, float* result, \n",
    "                                  int width){\n",
    "\t\n",
    "\tint col = threadIdx.x;\n",
    " \n",
    "\t// Check for thread out of bound access\n",
    "\tif (col < width){\n",
    "        for (int row = 0; row < width; ++row) {\n",
    "            float sum = 0;\t\n",
    "            for (int k = 0; k < width; ++k){\n",
    "    \t\t\tsum += matrix_a[row * width + k] * matrix_b[k * width + col];\n",
    "    \t\t}\n",
    "    \t\tresult[row * width + col] = sum;\n",
    "    \t}\n",
    "    }\n",
    "}\n",
    "\n",
    "torch::Tensor matrix_mul(torch::Tensor matrix_a, torch::Tensor matrix_b){\n",
    "\n",
    "    const auto width = matrix_a.size(0);\n",
    "    auto result =  torch::empty_like(matrix_a);\n",
    "\n",
    "    matrix_mul_kernel<<<1, width>>>(\n",
    "        matrix_a.data_ptr<float>(), matrix_b.data_ptr<float>(), result.data_ptr<float>(), width); // assume square matrix\n",
    "    return result;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "cpp_source = \"torch::Tensor matrix_mul(torch::Tensor matrix_a, torch::Tensor matrix_b);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "115ba8c9-2ec8-41fb-b9bc-c9e11b9b6d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_mul_extension_col = load_inline(\n",
    "    name='matrix_mul_extension_col',\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=['matrix_mul'],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\"-O2\"],\n",
    "    build_directory='tmp',\n",
    "    # extra_cuda_cflags=['--expt-relaxed-constexpr']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82f37459-f374-4b7e-a308-3bfda39762b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 30.,  36.,  42.],\n",
      "        [ 66.,  81.,  96.],\n",
      "        [102., 126., 150.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1., 2., 3], [4., 5., 6.], [7., 8., 9.]], device='cuda')\n",
    "b = torch.tensor([[1., 2., 3], [4., 5., 6.], [7., 8., 9.]], device='cuda')\n",
    "print(matrix_mul_extension_col.matrix_mul(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6ee5bef-2ccb-4eeb-8d90-d235631cabf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.87 µs ± 37.1 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "matrix_mul_extension_col.matrix_mul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10feb81-d771-40ff-b6ef-996aafe02f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_func(matrix_mul_extension.matrix_mul, *[a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16951e98-3219-4ff3-8afc-57b17670246f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 30.,  36.,  42.],\n",
       "        [ 66.,  81.,  96.],\n",
       "        [102., 126., 150.]], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d02e2-4e9d-4fac-83bc-11168a236ae3",
   "metadata": {},
   "source": [
    "### Matrix vec mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43c931fc-8ec7-477d-a630-307d6bf4d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_source = \"\"\"\n",
    "__global__ void matrix_vec_mul_kernel(const float* matrix_b, const float* vec_c, float* vec_a, int width){\n",
    "\t\n",
    "\tint idx = threadIdx.x;\n",
    " \n",
    "\t// Check for thread out of bound access\n",
    "\tif (idx < width){\n",
    "\t\tfloat sum = 0;\n",
    "\t\tfor (int col = 0; col < width; ++col) {\n",
    "\t\t\tsum += matrix_b[idx * width + col] * vec_c[col];\n",
    "\t\t}\n",
    "\t    vec_a[idx] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "torch::Tensor matrix_vec_mul(torch::Tensor matrix_b, torch::Tensor vec_c){\n",
    "\n",
    "    const auto width = matrix_b.size(0);\n",
    "    auto vec_a =  torch::empty_like(vec_c);\n",
    "\n",
    "    matrix_vec_mul_kernel<<<1, width>>>(\n",
    "        matrix_b.data_ptr<float>(), vec_c.data_ptr<float>(), vec_a.data_ptr<float>(), width); // assume square matrix\n",
    "    return vec_a;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "cpp_source = \"torch::Tensor matrix_vec_mul(torch::Tensor matrix_b, torch::Tensor vec_c);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13811151-9a83-4f02-a87b-094d5d5ee896",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_vec_mul_extension_col = load_inline(\n",
    "    name='matrix_vec_mul_extension_col',\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=['matrix_vec_mul'],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\"-O2\"],\n",
    "    build_directory='tmp',\n",
    "    # extra_cuda_cflags=['--expt-relaxed-constexpr']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72a0fe55-6331-4180-9b5f-095b9de6cfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 30.],\n",
      "        [ 66.],\n",
      "        [102.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]], device='cuda')\n",
    "b = torch.tensor([[1.], [4.], [7]], device='cuda')\n",
    "print(matrix_vec_mul_extension_col.matrix_vec_mul(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a608445-52e3-42cc-a9c7-2234da938704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.24 µs ± 40.8 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "matrix_vec_mul_extension_col.matrix_vec_mul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ad05770-149a-498f-a147-77a326b3d5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 30.],\n",
       "        [ 66.],\n",
       "        [102.]], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abfdd72-a3d6-4b39-856f-ad8ea20e1a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_func(matrix_vec_mul_extension_col.matrix_vec_mul, *[a,b])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
